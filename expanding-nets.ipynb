{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import copy\n",
    "import random as rd \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Subset\n",
    "from torch.optim import Adam, SGD \n",
    "from torch.utils.data import Subset, Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score \n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([ \n",
    "    torchvision.transforms.Resize((224, 224)), \n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = int(0.2 * len(dataset))  # Use 20% of the dataset\n",
    "\n",
    "# Randomly select a subset of the dataset\n",
    "subset_indices = torch.randperm(len(dataset))[:subset_size]\n",
    "subset = Subset(dataset, subset_indices)\n",
    "\n",
    "# Now split the subset into training, validation, and test sets\n",
    "total_size = len(subset)\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(subset, [int(total_size * 0.8), int(total_size * 0.1), int(total_size * 0.1)])\n",
    "\n",
    "# Print sizes\n",
    "print(\"Subset size: \", subset_size)\n",
    "print(\"Train size: \", len(train_data))\n",
    "print(\"Val size: \", len(val_data))\n",
    "print(\"Test size: \", len(test_data))\n",
    "\n",
    "# Define DataLoader for each set\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
